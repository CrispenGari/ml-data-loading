{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to PySpack\n",
        "\n",
        "In this notebook we are going to go with the basics of PySpacks. First you need to run the following code cell and make sure that you have the spacks context."
      ],
      "metadata": {
        "id": "-u4rYu8W1yxT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "RmVlBBnF1t_u",
        "outputId": "fe6ff76a-2a69-4a58-eb5c-aff191ca0cbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SparkContext master=local[*] appName=YourTest>"
            ],
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://87d403be08c3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.0.0</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>YourTest</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# innstall java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "\n",
        "# set your spark folder to your system path environment.\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "spark_conf = SparkConf()\\\n",
        "  .setAppName(\"YourTest\")\\\n",
        "  .setMaster(\"local[*]\")\n",
        "\n",
        "sc = SparkContext.getOrCreate(spark_conf)\n",
        "sc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create `1000` numbers using the range function."
      ],
      "metadata": {
        "id": "jmgTQ1bb1xIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums = list(range(0, 100000))\n",
        "len(nums)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ua7GbXgb4B_k",
        "outputId": "6734fdb6-5ab1-4132-9ce8-33d8497a6951"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use our spacks to do distributed computing by creating something called an rdd. The following code will create a `Resilient Distributed Dataset (RDD)`"
      ],
      "metadata": {
        "id": "GEfdeDSM4sdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums_rdd = sc.parallelize(nums)\n",
        "nums_rdd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-Oiq8Oi4B80",
        "outputId": "459d4d07-5dbb-4a12-8d04-060e75b33921"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, how can we get the data that is in this RDD. We can use the method called `collect()` which is not efficient but however it takes all the data in the dataset."
      ],
      "metadata": {
        "id": "9Io47uip5FlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums_rdd.collect()[:7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXu6BxrB4B5v",
        "outputId": "e4615315-9e8d-4e4a-d0d6-fb98b9f9a3c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method called `take` allows us to take certain number of samples in the dataset"
      ],
      "metadata": {
        "id": "OtVA0Ul34B26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nums_rdd.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0xoxkzX5jmC",
        "outputId": "0c8e94f1-18aa-41e1-c2d4-b35e334dbeba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the method called `map` which maps through the elements of the dataset and returns a modified version of the data. Here is an example that square the numbers that are in the rdd."
      ],
      "metadata": {
        "id": "cvM7ao125kaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_rdd = nums_rdd.map(lambda x: x*x)\n",
        "squared_rdd.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23a80e3757nO",
        "outputId": "5589824b-5ba4-4d76-cf24-fe1f2b6e4042"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a second example that returns a number after it has been squared and the the total number of digits it has as a python tuple."
      ],
      "metadata": {
        "id": "Lr9pD3Ml6BDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_digits_rdd = squared_rdd.map(lambda x: (x, len(str(x))))\n",
        "total_digits_rdd.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBlBurHI6RpE",
        "outputId": "538faaad-348f-455e-d174-361803d4c8b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (1, 1), (4, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the filter method to remove elements based on a condition in this rdd. Let's say we want to remove all the elements that does not have even number of digits in our rdd we can do it as follows:"
      ],
      "metadata": {
        "id": "n8aM8J9d6Vvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "even_digits_rdd = total_digits_rdd.filter(lambda x: x[1] % 2 == 0)\n",
        "even_digits_rdd.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwfi7gJx6uBQ",
        "outputId": "471b1f49-ab48-40b9-de56-e65354e2cfca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16, 2), (25, 2), (36, 2)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we want to flip the pairs, so that we have number of digits paired to a number we can do it as follows:"
      ],
      "metadata": {
        "id": "OTXub6116ijA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flipped_pairs_rdd = even_digits_rdd.map(lambda x: (x[1], x[0]))\n",
        "flipped_pairs_rdd.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbrhqmYy6-_V",
        "outputId": "64ca364c-4f32-47d9-e805-42022b7cb23a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 16), (2, 25), (2, 36)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the `groupByKey` method to group elements in an rdd based on a key. Here is an example."
      ],
      "metadata": {
        "id": "arDiitZS7DLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_rdd = flipped_pairs_rdd.groupByKey()\n",
        "grouped_rdd.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl1qf7yL7CQM",
        "outputId": "67dde90d-4cb7-43ce-db7f-bd0d7a26643b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, <pyspark.resultiterable.ResultIterable at 0x7e455c3f1ff0>),\n",
              " (4, <pyspark.resultiterable.ResultIterable at 0x7e455c3f3610>),\n",
              " (6, <pyspark.resultiterable.ResultIterable at 0x7e455c3f3820>)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our keys are correctly paired however the value is a `pyspark.resultiterable.ResultIterable` object. We can use the map function to convert that to a list."
      ],
      "metadata": {
        "id": "pBMo9wJ97Nez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_and_mapped_to_list_rdd = grouped_rdd.map(lambda x: (x[0], list(x[1])))\n",
        "grouped_and_mapped_to_list_rdd.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_2tlEqD7i_N",
        "outputId": "b85f3bba-7a6a-4708-a1b2-c4f31682abbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, [16, 25, 36, 49, 64, 81])]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can return the key and the avarage of it's values, for that we can use the `map` function to do that."
      ],
      "metadata": {
        "id": "wccQcKLv7sT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avaraged_rdd = grouped_and_mapped_to_list_rdd.map(lambda x: (x[0], sum(x[1])/len(x[1])))\n",
        "avaraged_rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yECrCq-77_cX",
        "outputId": "0260b3a2-6776-4042-e263-6622df01279d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(2, 45.166666666666664),\n",
              " (4, 4675.5),\n",
              " (6, 471838.0),\n",
              " (8, 47204941.666666664),\n",
              " (10, 4720705565.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_1ayZQRd8Gya"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}